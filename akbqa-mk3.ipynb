{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9339793,"sourceType":"datasetVersion","datasetId":5543066}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","scrolled":true,"execution":{"iopub.status.busy":"2024-09-08T08:47:53.072129Z","iopub.execute_input":"2024-09-08T08:47:53.072994Z","iopub.status.idle":"2024-09-08T08:47:53.838594Z","shell.execute_reply.started":"2024-09-08T08:47:53.072946Z","shell.execute_reply":"2024-09-08T08:47:53.837661Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":"directory_path = '/kaggle/input/business-json/Task_3_aud_files/kaggle/working/Task_3_aud_files'\n\nnum_files = len([name for name in os.listdir(directory_path) if os.path.isfile(os.path.join(directory_path, name))])\n\nprint(f'Total number of files in the directory: {num_files}')\n","metadata":{"execution":{"iopub.status.busy":"2024-09-08T08:47:53.840419Z","iopub.execute_input":"2024-09-08T08:47:53.840867Z","iopub.status.idle":"2024-09-08T08:47:54.315258Z","shell.execute_reply.started":"2024-09-08T08:47:53.840840Z","shell.execute_reply":"2024-09-08T08:47:54.314219Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Total number of files in the directory: 1215\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!pip install torch torchaudio transformers","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-09-08T08:47:54.316397Z","iopub.execute_input":"2024-09-08T08:47:54.316689Z","iopub.status.idle":"2024-09-08T08:48:07.641997Z","shell.execute_reply.started":"2024-09-08T08:47:54.316662Z","shell.execute_reply":"2024-09-08T08:48:07.641079Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.1.2)\nRequirement already satisfied: torchaudio in /opt/conda/lib/python3.10/site-packages (2.1.2)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.42.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.5.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.23.4)\nRequirement already satisfied: numpy<2.0,>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.7.4)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import torchaudio\nimport torch\nimport librosa\nfrom transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\nfrom sklearn.model_selection import train_test_split\nfrom transformers import RobertaTokenizer\nfrom transformers import RobertaTokenizerFast\nfrom torch.utils.data import DataLoader, Dataset\nfrom transformers import RobertaForTokenClassification, AdamW, get_linear_schedule_with_warmup\nfrom transformers import GPT2Tokenizer, GPT2LMHeadModel\nfrom transformers import pipeline\nfrom torch.nn.utils.rnn import pad_sequence\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport ast","metadata":{"execution":{"iopub.status.busy":"2024-09-08T08:54:12.439855Z","iopub.execute_input":"2024-09-08T08:54:12.440641Z","iopub.status.idle":"2024-09-08T08:54:12.448899Z","shell.execute_reply.started":"2024-09-08T08:54:12.440606Z","shell.execute_reply":"2024-09-08T08:54:12.447933Z"},"trusted":true},"outputs":[],"execution_count":22},{"cell_type":"code","source":"class AudioToTextDataset(Dataset):\n    def __init__(self, csv_file, audio_dir, processor, device, target_sample_rate=16000,sample_fraction =  1, k_sec = 7):\n#         self.data = pd.read_csv(csv_file).sample(frac=sample_fraction, random_state=42).reset_index(drop=True)\n        self.data = pd.read_csv(csv_file)\n        self.audio_dir = audio_dir\n        self.processor = processor\n        self.device = device\n        self.target_sample_rate = target_sample_rate\n        self.cutoff = k_sec\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx, k_seconds=None):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n        q_id = self.data.iloc[idx]['QID']\n        all_sent_str = self.data.iloc[idx]['all_sentences']\n        all_sent = ast.literal_eval(all_sent_str)\n        audio_paths = []\n        inputs = []\n        k_seconds = self.cutoff\n        for i in range(len(all_sent)):\n            pth = f\"{self.audio_dir}/Sentence_{q_id}_{i}.wav\"\n            audio_paths.append(pth)\n            waveform1, sample_rate1 = torchaudio.load(pth)\n\n            if sample_rate1 != self.target_sample_rate:\n                resampler1 = torchaudio.transforms.Resample(orig_freq=sample_rate1, new_freq=self.target_sample_rate)\n                waveform1 = resampler1(waveform1)\n\n            if k_seconds is not None:\n                num_samples = int(self.target_sample_rate * k_seconds)\n                waveform1 = waveform1[:, :num_samples]\n\n            inputs1 = self.processor(waveform1.squeeze().numpy(), sampling_rate=self.target_sample_rate, return_tensors=\"pt\", padding=True)\n            inputs1 = {key: val.to(self.device) for key, val in inputs1.items()}\n            inputs.append(inputs1)\n\n        return inputs, q_id\n\n    def generate_asr_outputs(self, model):\n        results = []\n        model.eval()\n\n        for idx in range(len(self)):\n            inputs_list, q_id = self[idx]\n\n            # Process each sentence independently\n            sentence_transcriptions = []\n            sent_ids = []\n            for j,inputs in enumerate(inputs_list):\n                with torch.no_grad():\n                    logits = model(**inputs).logits\n                predicted_ids = torch.argmax(logits, dim=-1)\n                transcription = self.processor.batch_decode(predicted_ids)[0]\n                sentence_transcriptions.append(transcription)\n                sent_ids.append(j)\n            # Append transcription for each input sentence\n            results.append({\n                'QID': q_id,\n                'transcriptions': sentence_transcriptions,\n                'Sentence_ids': sent_ids\n            })\n\n            if idx == 0:\n                print(sentence_transcriptions)\n            \n        return pd.DataFrame(results)\n            \n        # Return the results as a DataFrame or a list\n#         return results\n#             results.append(\n#             {\n#                 'Sentence_1_transcript': transcription1,\n#                 'Sentence_2_transcript': transcription2,\n#                 'QID': q_id\n#             }\n#             )\n#         return pd.DataFrame(results)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-08T09:05:40.836414Z","iopub.execute_input":"2024-09-08T09:05:40.836854Z","iopub.status.idle":"2024-09-08T09:05:40.853142Z","shell.execute_reply.started":"2024-09-08T09:05:40.836812Z","shell.execute_reply":"2024-09-08T09:05:40.851986Z"},"trusted":true},"outputs":[],"execution_count":38},{"cell_type":"code","source":"\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n\nprocessor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\nasr_model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\").to(device)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-09-08T09:06:01.365434Z","iopub.execute_input":"2024-09-08T09:06:01.366163Z","iopub.status.idle":"2024-09-08T09:06:02.003915Z","shell.execute_reply.started":"2024-09-08T09:06:01.366131Z","shell.execute_reply":"2024-09-08T09:06:02.003102Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"},{"name":"stderr","text":"Some weights of the model checkpoint at facebook/wav2vec2-base-960h were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.masked_spec_embed']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"csv_file = \"/kaggle/input/business-json/Task_3_data.csv\"\naudio_dir = \"/kaggle/input/business-json/Task_3_aud_files/kaggle/working/Task_3_aud_files\"\ndf = pd.read_csv(csv_file)\nprint(df.iloc[0]['all_sentences'])\n\ndataset = AudioToTextDataset(csv_file, audio_dir, processor, device)\n\n# dataset.generate_asr_outputs(asr_model)\ndf_asr_outputs = dataset.generate_asr_outputs(asr_model)\n\n# df_train, df_test = train_test_split(df_asr_outputs, test_size=0.2, random_state=42)\n\n# print(df_train.head())","metadata":{"execution":{"iopub.status.busy":"2024-09-08T09:06:02.086601Z","iopub.execute_input":"2024-09-08T09:06:02.087261Z","iopub.status.idle":"2024-09-08T09:07:01.421989Z","shell.execute_reply.started":"2024-09-08T09:06:02.087226Z","shell.execute_reply":"2024-09-08T09:07:01.420929Z"},"trusted":true},"outputs":[{"name":"stdout","text":"['Nissan has Yoshisuke Aikawa as CEO.', 'Chevrolet is a type of Auto showroom.', 'Telstra is a type of Telecom store.', 'DATS petrol stations has origin country Belgium.', 'Halliburton has Erle P. Halliburton as CEO.', 'Public Bank Berhad has Teh Hong Piow as CEO.', 'Barclays is a type of Bank.', 'Total S.A. was established on 1924-03-28.', 'Great Canadian Dollar Store was established on 1993-01-01.', \"Freddy's Frozen Custard is a type of Restaurant.\", 'Franprix is a type of Retail store.', 'Mango was established on 1984-01-01.', 'Indian Oil Corporation was established on 1964-01-01.', 'Kasikornbank has Choti Lamsam as CEO.']\n['NISSON HAS OSHASU ACAWAY I SEO', 'CHEVRULIT IS A TYPE OF ARTOCHORUM', 'TELSTRAY IS A TYPE OF TELECHUM STORE', \"DAD'S PATROL STATIONS HAS ORIGIN COUNTRY BELGIUM\", 'HALIBURTON HES ERLUP HALIBURTON ASSEO', 'PUBLIC BANK BERHAD HASTEJON PIO AS SEO', \"BARCLAY'S IS A TYPE OF BANK\", 'TOTAL SAY WAS ESTABLISHED ON NINETEEN TWENTY FOUR MINUSTS THREE MINUSTS TWENTY EIGHT', 'GREAT CANADIAN DOLLAR STORE WAS ESTABLISHED ON NINETEEN NINETY THREE MINISONEMINUS ONE', \"FREDDY'S FROZEN CUSTARD IS A TYPE OF RESTORANT\", \"FRANPRIXES A TYPE OF RETAIL'S STORE\", 'MANGO WAS ESTABLISHED ON NINETEEN EIGHTY FORMINOUS ONOMINUS AN AAS A C', 'INDIAN OIL CORPORATION WAS ESTABLISHED ON NINETEEN SIXTY FORMINOUS OR EMINOUS WAN', 'CASSICORN BANK HAS TOTE LAMBSAM ASCIO']\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"print(df_asr_outputs.head())","metadata":{"execution":{"iopub.status.busy":"2024-09-08T09:08:08.583928Z","iopub.execute_input":"2024-09-08T09:08:08.584764Z","iopub.status.idle":"2024-09-08T09:08:08.593909Z","shell.execute_reply.started":"2024-09-08T09:08:08.584728Z","shell.execute_reply":"2024-09-08T09:08:08.592855Z"},"trusted":true},"outputs":[{"name":"stdout","text":"   QID                                     transcriptions  \\\n0    0  [NISSON HAS OSHASU ACAWAY I SEO, CHEVRULIT IS ...   \n1    1  [HARDY IS A TYPE OF ARTOSHORROOM, FUGIT HAS HE...   \n2    2  [NISSON HASIOSHA SUK BAKE AWAY AS SEO, IN DAY ...   \n3    3  [CAM MOTORS HAS HEADQUARTERS IN SEAL, UNDAY MO...   \n4    4  [NISSON HAS YOSHA SUC ACAWAY AS SEO, PORSCHI I...   \n\n                                     Sentence_ids  \n0  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]  \n1                     [0, 1, 2, 3, 4, 5, 6, 7, 8]  \n2      [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]  \n3                        [0, 1, 2, 3, 4, 5, 6, 7]  \n4              [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]  \n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"df_asr_outputs.to_csv(\"task_3_asr_out.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-09-08T09:08:10.706286Z","iopub.execute_input":"2024-09-08T09:08:10.707154Z","iopub.status.idle":"2024-09-08T09:08:10.716292Z","shell.execute_reply.started":"2024-09-08T09:08:10.707121Z","shell.execute_reply":"2024-09-08T09:08:10.715500Z"},"trusted":true},"outputs":[],"execution_count":45},{"cell_type":"code","source":"entities_csv = \"/kaggle/input/business-json/data (3).csv\" \nentities_df = pd.read_csv(entities_csv) \ntrain_df = df_train.copy()\nmerged_df = pd.merge(train_df, entities_df, left_on=\"Sentence_ID\", right_on=\"Sentence_id\", how=\"inner\")\ntokenizer = RobertaTokenizerFast.from_pretrained(\"roberta-base\")\n\ndef tokenize_and_align_labels(text, entities):\n    tokens = tokenizer(text, truncation=True, return_offsets_mapping=True, return_tensors=\"pt\")\n    labels = [\"O\"] * len(tokens.input_ids[0]) \n\n    for entity in eval(entities):\n        mention = entity[\"mention\"]\n        link = entity[\"link\"]\n\n        start_idx = text.find(mention)\n        end_idx = start_idx + len(mention)\n\n        for idx, (start, end) in enumerate(tokens[\"offset_mapping\"][0]):\n            if start >= start_idx and end <= end_idx:\n                if start == start_idx:\n                    labels[idx] = \"B-\" + link  \n                else:\n                    labels[idx] = \"I-\" + link  \n                    \n    return tokens.input_ids[0], labels\n\n\ntokenized_texts_and_labels = []\nfor idx, row in merged_df.iterrows():\n    text = row[\"ASR_Output\"]\n    entities = row[\"entities\"]  \n    input_ids, labels = tokenize_and_align_labels(text, entities)\n    tokenized_texts_and_labels.append((input_ids, labels))\n\n\ntrain_data = pd.DataFrame(tokenized_texts_and_labels, columns=[\"input_ids\", \"labels\"])\n\n\nprint(train_data.head())","metadata":{"execution":{"iopub.status.busy":"2024-08-21T14:16:24.535517Z","iopub.execute_input":"2024-08-21T14:16:24.535781Z","iopub.status.idle":"2024-08-21T14:16:27.146974Z","shell.execute_reply.started":"2024-08-21T14:16:24.535757Z","shell.execute_reply":"2024-08-21T14:16:27.146103Z"},"trusted":true},"outputs":[{"name":"stdout","text":"                                           input_ids  \\\n0  [tensor(0), tensor(2688), tensor(387), tensor(...   \n1  [tensor(0), tensor(387), tensor(1889), tensor(...   \n2  [tensor(0), tensor(771), tensor(2118), tensor(...   \n3  [tensor(0), tensor(25912), tensor(1301), tenso...   \n4  [tensor(0), tensor(495), tensor(2606), tensor(...   \n\n                                              labels  \n0  [I-Q422, I-Q422, I-Q422, I-Q422, I-Q907, O, O,...  \n1  [I-Q983, I-Q983, I-Q983, I-Q983, I-Q983, I-Q98...  \n2  [I-Q5, I-Q5, I-Q5, I-Q5, O, O, O, O, O, O, O, ...  \n3  [I-Q400, I-Q400, I-Q400, I-Q400, O, O, O, O, O...  \n4  [I-Q596, I-Q596, I-Q596, I-Q596, I-Q596, I-Q59...  \n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"unique_labels = sorted({label for labels in train_data['labels'] for label in labels})\nlabel_map = {label: idx for idx, label in enumerate(unique_labels)}\n\ntrain_data['labels'] = train_data['labels'].apply(lambda x: [label_map[label] for label in x])\n\nclass NERDataset(Dataset):\n    def __init__(self, df):\n        self.input_ids = df['input_ids'].values\n        self.labels = df['labels'].values\n\n    def __len__(self):\n        return len(self.input_ids)\n\n    def __getitem__(self, idx):\n        return torch.tensor(self.input_ids[idx], dtype=torch.long), torch.tensor(self.labels[idx], dtype=torch.long)\n\ndef collate_fn(batch):\n    input_ids, labels = zip(*batch)\n    \n    input_ids_padded = pad_sequence(input_ids, batch_first=True, padding_value=tokenizer.pad_token_id)\n    labels_padded = pad_sequence(labels, batch_first=True, padding_value=-100)  \n    \n    return input_ids_padded, labels_padded\n\n\ntrain_df, val_df = train_test_split(train_data, test_size=0.1, random_state=42)\n\ntrain_dataset = NERDataset(train_df)\nval_dataset = NERDataset(val_df)\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=collate_fn)\nval_dataloader = DataLoader(val_dataset, batch_size=16, collate_fn=collate_fn)","metadata":{"execution":{"iopub.status.busy":"2024-08-21T14:16:27.149356Z","iopub.execute_input":"2024-08-21T14:16:27.149661Z","iopub.status.idle":"2024-08-21T14:16:27.170528Z","shell.execute_reply.started":"2024-08-21T14:16:27.149635Z","shell.execute_reply":"2024-08-21T14:16:27.169704Z"},"trusted":true},"outputs":[],"execution_count":33},{"cell_type":"code","source":"bert_model = RobertaForTokenClassification.from_pretrained(\"roberta-base\", num_labels=len(unique_labels))\nbert_model = bert_model.to(device)\n\noptimizer = AdamW(bert_model.parameters(), lr=2e-5, eps=1e-8)\ntotal_steps = len(train_dataloader) * 4 \nscheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)","metadata":{"execution":{"iopub.status.busy":"2024-08-21T14:16:27.171527Z","iopub.execute_input":"2024-08-21T14:16:27.171780Z","iopub.status.idle":"2024-08-21T14:16:27.765214Z","shell.execute_reply.started":"2024-08-21T14:16:27.171757Z","shell.execute_reply":"2024-08-21T14:16:27.764444Z"},"trusted":true},"outputs":[{"name":"stderr","text":"Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"epochs = 10\nfor epoch in range(epochs):\n    bert_model.train()\n    total_loss = 0\n\n    for batch in train_dataloader:\n        input_ids, labels = batch\n        input_ids = input_ids.to(device)\n        labels = labels.to(device)\n\n        bert_model.zero_grad()\n\n        outputs = bert_model(input_ids=input_ids, labels=labels)\n        loss = outputs.loss\n        total_loss += loss.item()\n\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(bert_model.parameters(), max_norm=1.0)\n        optimizer.step()\n        scheduler.step()\n\n    avg_train_loss = total_loss / len(train_dataloader)\n    print(f\"Epoch {epoch + 1}, Average Training Loss: {avg_train_loss}\")\n\n    bert_model.eval()\n    val_loss = 0\n\n    with torch.no_grad():\n        for batch in val_dataloader:\n            input_ids, labels = batch\n            input_ids = input_ids.to(device)\n            labels = labels.to(device)\n\n            outputs = bert_model(input_ids=input_ids, labels=labels)\n            loss = outputs.loss\n            val_loss += loss.item()\n\n    avg_val_loss = val_loss / len(val_dataloader)\n    print(f\"Epoch {epoch + 1}, Average Validation Loss: {avg_val_loss}\")\n\nprint(\"Training complete.\")","metadata":{"execution":{"iopub.status.busy":"2024-08-21T14:16:27.766409Z","iopub.execute_input":"2024-08-21T14:16:27.766696Z","iopub.status.idle":"2024-08-21T14:19:14.832218Z","shell.execute_reply.started":"2024-08-21T14:16:27.766672Z","shell.execute_reply":"2024-08-21T14:19:14.831190Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Epoch 1, Average Training Loss: 3.078959424956506\nEpoch 1, Average Validation Loss: 2.653327992984227\nEpoch 2, Average Training Loss: 2.457566067952068\nEpoch 2, Average Validation Loss: 2.331597183431898\nEpoch 3, Average Training Loss: 2.2940263868379995\nEpoch 3, Average Validation Loss: 2.2603525604520525\nEpoch 4, Average Training Loss: 2.195709489974655\nEpoch 4, Average Validation Loss: 2.2232161590031216\nEpoch 5, Average Training Loss: 2.178873149286799\nEpoch 5, Average Validation Loss: 2.2232161590031216\nEpoch 6, Average Training Loss: 2.1746659889942457\nEpoch 6, Average Validation Loss: 2.2232161590031216\nEpoch 7, Average Training Loss: 2.1874842683808144\nEpoch 7, Average Validation Loss: 2.2232161590031216\nEpoch 8, Average Training Loss: 2.1750024497008122\nEpoch 8, Average Validation Loss: 2.2232161590031216\nEpoch 9, Average Training Loss: 2.183828016289142\nEpoch 9, Average Validation Loss: 2.2232161590031216\nEpoch 10, Average Training Loss: 2.178804987618903\nEpoch 10, Average Validation Loss: 2.2232161590031216\nTraining complete.\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"tokenizer = RobertaTokenizerFast.from_pretrained(\"roberta-base\")\n\ntest_dataset = NERDataset(train_data)  \ntest_dataloader = DataLoader(test_dataset, batch_size=16, collate_fn=collate_fn)\n\nbert_model.eval()\n\npredictions = []\ntrue_labels = []\n\nwith torch.no_grad():\n    for batch in test_dataloader:\n        input_ids, labels = batch\n        input_ids = input_ids.to(device)\n        labels = labels.to(device)\n\n        outputs = bert_model(input_ids=input_ids)\n        logits = outputs.logits\n\n        preds = torch.argmax(logits, dim=-1)\n        \n        for i in range(input_ids.size(0)):\n            sentence = tokenizer.decode(input_ids[i], skip_special_tokens=True)\n            \n            pred_labels = preds[i].cpu().numpy()\n            label_ids = labels[i].cpu().numpy()\n            \n            pred_labels = [unique_labels[id] for id in pred_labels if id != -100]\n            true_labels = [unique_labels[id] for id in label_ids if id != -100]\n            \n            predictions.append({\n                \"sentence\": sentence,\n                \"predicted_entities\": pred_labels\n            })\n            true_labels.append({\n                \"sentence\": sentence,\n                \"true_entities\": true_labels\n            })\n\npredictions_df = pd.DataFrame(predictions)\ntrue_labels_df = pd.DataFrame(true_labels)\n\nprint(\"Predictions and true labels saved.\")","metadata":{"execution":{"iopub.status.busy":"2024-08-21T14:19:14.833353Z","iopub.execute_input":"2024-08-21T14:19:14.833620Z","iopub.status.idle":"2024-08-21T14:19:19.717382Z","shell.execute_reply.started":"2024-08-21T14:19:14.833595Z","shell.execute_reply":"2024-08-21T14:19:19.716432Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Predictions and true labels saved.\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"print(predictions_df)","metadata":{"execution":{"iopub.status.busy":"2024-08-21T14:19:19.718785Z","iopub.execute_input":"2024-08-21T14:19:19.719570Z","iopub.status.idle":"2024-08-21T14:19:19.729928Z","shell.execute_reply.started":"2024-08-21T14:19:19.719532Z","shell.execute_reply":"2024-08-21T14:19:19.729042Z"},"trusted":true},"outputs":[{"name":"stdout","text":"                                               sentence  \\\n0                 IDBUD BANK HAS HEADQUARTERS IN MUMBAY   \n1        BAN IN A REPUBLIC IS A TYPE OF APPERIL'S STORE   \n2     WALGREENS WAS ESTABLISHED ON NINETEEN O ONEMIN...   \n3     ATAZON WAS ESTABLISHED ON NINETEEN SEVENTY NIN...   \n4     DAD'S PATROL STATIONS IS A TYPE OF PATROL STATION   \n...                                                 ...   \n2095       HE O BIGILO IS FROM UNITED STATES OF AMERICA   \n2096     BRICKOAT HAS HEADQUARTERS IN LONGPOMP SIR ORGE   \n2097  CODA AUTO PRODUCES CAR CODA FABIA CODA RAPI TW...   \n2098    AT ANT HAS HEADQUARTERS AND WOULD TAKE RE TOWER   \n2099  CASIO BELONGS TO THE ELECTRONIC'S INDUSTRY IND...   \n\n                                     predicted_entities  \n0     [I-Q1085, I-Q892, I-Q1085, I-Q892, O, O, O, O,...  \n1     [I-Q94, I-Q94, I-Q94, I-Q94, I-Q94, I-Q94, I-Q...  \n2     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n3     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n4     [I-Q801, I-Q801, I-Q801, I-Q801, I-Q801, I-Q80...  \n...                                                 ...  \n2095  [I-Q977, I-Q977, I-Q977, I-Q977, I-Q977, I-Q97...  \n2096  [I-Q1085, I-Q1085, I-Q1085, I-Q1085, O, O, O, ...  \n2097  [I-Q892, I-Q892, I-Q892, I-Q892, I-Q892, I-Q89...  \n2098  [I-Q563, I-Q563, I-Q563, O, O, O, O, O, O, O, ...  \n2099  [I-Q1262, I-Q1262, I-Q1262, I-Q1262, I-Q1262, ...  \n\n[2100 rows x 2 columns]\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"asr_processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-large-960h\")\n\nroberta_tokenizer = RobertaTokenizerFast.from_pretrained(\"roberta-base\")\n\n\ngpt2_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\ngpt2_model = GPT2LMHeadModel.from_pretrained(\"gpt2\").to(device)\n\nknowledge_df = predictions_df.copy()\n\ndef qa_pipeline(audio_path, question):\n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    \n    audio, _ = librosa.load(audio_path, sr=16000)\n    \n    audio_input = asr_processor(audio, return_tensors=\"pt\", padding=True, sampling_rate=16000).to(device)\n    with torch.no_grad():\n        logits = asr_model(**audio_input).logits\n    predicted_ids = torch.argmax(logits, dim=-1)\n    transcription = asr_processor.decode(predicted_ids[0].cpu())\n    print(f\"Transcription: {transcription}\")\n    \n    inputs = roberta_tokenizer(transcription, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n    with torch.no_grad():\n        outputs = bert_model(**inputs)\n    predictions = torch.argmax(outputs.logits, dim=-1).squeeze().cpu().tolist()\n    \n\n    labels = roberta_tokenizer.decode(predictions)\n    print(labels)\n    entity_ids = {label.split('-')[1] for label in labels if label.startswith('I-')}\n\n    relevant_sentences = []\n    for entity_id in entity_ids:\n        relevant_knowledge = knowledge_df[knowledge_df['predicted_entities'].apply(lambda x: any(e for e in x if e.endswith(entity_id)))]['sentence'].tolist()\n        relevant_sentences.extend(relevant_knowledge)\n    \n    knowledge_text = \" \".join(relevant_sentences)\n    print(knowledge_text)\n    input_text = f\"Question: {question}\\nContext: {knowledge_text}\"\n    inputs = gpt2_tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n    \n    with torch.no_grad():\n        outputs = gpt2_model.generate(inputs, max_length=150, num_return_sequences=1, early_stopping=True)\n    answer = gpt2_tokenizer.decode(outputs[0].cpu(), skip_special_tokens=True)\n    \n    return answer\n\naudio_path = \"/kaggle/input/business-json/aud_files/kaggle/working/TTS/aud_files/sentence_1.wav\"\nquestion = \"What is Carl's Jr.?\"\nanswer = qa_pipeline(audio_path, question)\nprint(f\"Answer: {answer}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-21T14:33:27.686091Z","iopub.execute_input":"2024-08-21T14:33:27.686472Z","iopub.status.idle":"2024-08-21T14:33:29.927491Z","shell.execute_reply.started":"2024-08-21T14:33:27.686443Z","shell.execute_reply":"2024-08-21T14:33:29.926601Z"},"trusted":true},"outputs":[{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Transcription: CARL'S JUNIOR IS A TYPE OF RESTORENT\n shooting light light light light light light light light light light light light light light shooting\n\nAnswer: Question: What is Carl's Jr.?\nContext:  Carl's Jr. is a fictional character in the popular TV series, The Simpsons.  He is a young man who is raised by his father, Carl, and his mother, Mary.  He is a very intelligent man, and he is a very good friend of his father.  He is a very good friend of his mother, and he is a very good friend of his father.  He is a very good friend of his father's family, and he is a very good friend of his mother's family.  He is a very good friend of his father's family, and he is a very good friend of his mother's family. \n","output_type":"stream"}],"execution_count":50},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}