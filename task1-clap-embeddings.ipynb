{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9357046,"sourceType":"datasetVersion","datasetId":5543066}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","scrolled":true,"execution":{"iopub.status.busy":"2024-09-12T08:38:07.177513Z","iopub.execute_input":"2024-09-12T08:38:07.178080Z","iopub.status.idle":"2024-09-12T08:38:07.184702Z","shell.execute_reply.started":"2024-09-12T08:38:07.178025Z","shell.execute_reply":"2024-09-12T08:38:07.183405Z"},"trusted":true},"outputs":[],"execution_count":41},{"cell_type":"code","source":"# Install pypi pacakge\n!pip install msclap\n\n# Or Install latest (unstable) git source\n# !pip install git+https://github.com/microsoft/CLAP.git","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-09-12T08:38:09.930470Z","iopub.execute_input":"2024-09-12T08:38:09.931532Z","iopub.status.idle":"2024-09-12T08:38:26.190761Z","shell.execute_reply.started":"2024-09-12T08:38:09.931482Z","shell.execute_reply":"2024-09-12T08:38:26.189360Z"},"trusted":true},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: msclap in /opt/conda/lib/python3.10/site-packages (1.3.3)\nRequirement already satisfied: librosa<0.11.0,>=0.10.1 in /opt/conda/lib/python3.10/site-packages (from msclap) (0.10.2.post1)\nRequirement already satisfied: numba<0.59.0,>=0.58.0 in /opt/conda/lib/python3.10/site-packages (from msclap) (0.58.1)\nRequirement already satisfied: numpy<2.0.0,>=1.23.0 in /opt/conda/lib/python3.10/site-packages (from msclap) (1.26.4)\nRequirement already satisfied: pandas<3.0.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from msclap) (2.2.2)\nRequirement already satisfied: pyyaml<7.0.0,>=6.0.1 in /opt/conda/lib/python3.10/site-packages (from msclap) (6.0.2)\nRequirement already satisfied: scikit-learn<2.0.0,>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from msclap) (1.5.2)\nRequirement already satisfied: torch<3.0.0,>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from msclap) (2.1.2)\nRequirement already satisfied: torchaudio<3.0.0,>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from msclap) (2.1.2)\nRequirement already satisfied: torchlibrosa<0.2.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from msclap) (0.1.0)\nRequirement already satisfied: torchvision<0.17.0,>=0.16.0 in /opt/conda/lib/python3.10/site-packages (from msclap) (0.16.2)\nRequirement already satisfied: tqdm<5.0.0,>=4.66.1 in /opt/conda/lib/python3.10/site-packages (from msclap) (4.66.4)\nRequirement already satisfied: transformers<5.0.0,>=4.34.0 in /opt/conda/lib/python3.10/site-packages (from msclap) (4.44.0)\nRequirement already satisfied: audioread>=2.1.9 in /opt/conda/lib/python3.10/site-packages (from librosa<0.11.0,>=0.10.1->msclap) (3.0.1)\nRequirement already satisfied: scipy>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from librosa<0.11.0,>=0.10.1->msclap) (1.14.0)\nRequirement already satisfied: joblib>=0.14 in /opt/conda/lib/python3.10/site-packages (from librosa<0.11.0,>=0.10.1->msclap) (1.4.2)\nRequirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.10/site-packages (from librosa<0.11.0,>=0.10.1->msclap) (5.1.1)\nRequirement already satisfied: soundfile>=0.12.1 in /opt/conda/lib/python3.10/site-packages (from librosa<0.11.0,>=0.10.1->msclap) (0.12.1)\nRequirement already satisfied: pooch>=1.1 in /opt/conda/lib/python3.10/site-packages (from librosa<0.11.0,>=0.10.1->msclap) (1.8.2)\nRequirement already satisfied: soxr>=0.3.2 in /opt/conda/lib/python3.10/site-packages (from librosa<0.11.0,>=0.10.1->msclap) (0.4.0)\nRequirement already satisfied: typing-extensions>=4.1.1 in /opt/conda/lib/python3.10/site-packages (from librosa<0.11.0,>=0.10.1->msclap) (4.12.2)\nRequirement already satisfied: lazy-loader>=0.1 in /opt/conda/lib/python3.10/site-packages (from librosa<0.11.0,>=0.10.1->msclap) (0.4)\nRequirement already satisfied: msgpack>=1.0 in /opt/conda/lib/python3.10/site-packages (from librosa<0.11.0,>=0.10.1->msclap) (1.0.8)\nRequirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba<0.59.0,>=0.58.0->msclap) (0.41.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0.0,>=2.0.0->msclap) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0.0,>=2.0.0->msclap) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0.0,>=2.0.0->msclap) (2024.1)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn<2.0.0,>=1.3.1->msclap) (3.5.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch<3.0.0,>=2.1.0->msclap) (3.15.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch<3.0.0,>=2.1.0->msclap) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch<3.0.0,>=2.1.0->msclap) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch<3.0.0,>=2.1.0->msclap) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch<3.0.0,>=2.1.0->msclap) (2024.6.1)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch<3.0.0,>=2.1.0->msclap) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch<3.0.0,>=2.1.0->msclap) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch<3.0.0,>=2.1.0->msclap) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch<3.0.0,>=2.1.0->msclap) (8.9.2.26)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch<3.0.0,>=2.1.0->msclap) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch<3.0.0,>=2.1.0->msclap) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch<3.0.0,>=2.1.0->msclap) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch<3.0.0,>=2.1.0->msclap) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch<3.0.0,>=2.1.0->msclap) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.18.1 in /opt/conda/lib/python3.10/site-packages (from torch<3.0.0,>=2.1.0->msclap) (2.18.1)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch<3.0.0,>=2.1.0->msclap) (12.1.105)\nRequirement already satisfied: triton==2.1.0 in /opt/conda/lib/python3.10/site-packages (from torch<3.0.0,>=2.1.0->msclap) (2.1.0)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<3.0.0,>=2.1.0->msclap) (12.6.68)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision<0.17.0,>=0.16.0->msclap) (2.32.3)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision<0.17.0,>=0.16.0->msclap) (9.5.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->msclap) (0.24.6)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->msclap) (21.3)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->msclap) (2024.5.15)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->msclap) (0.4.4)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->msclap) (0.19.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers<5.0.0,>=4.34.0->msclap) (3.1.2)\nRequirement already satisfied: platformdirs>=2.5.0 in /opt/conda/lib/python3.10/site-packages (from pooch>=1.1->librosa<0.11.0,>=0.10.1->msclap) (3.11.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas<3.0.0,>=2.0.0->msclap) (1.16.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision<0.17.0,>=0.16.0->msclap) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision<0.17.0,>=0.16.0->msclap) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision<0.17.0,>=0.16.0->msclap) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision<0.17.0,>=0.16.0->msclap) (2024.7.4)\nRequirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.10/site-packages (from soundfile>=0.12.1->librosa<0.11.0,>=0.10.1->msclap) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch<3.0.0,>=2.1.0->msclap) (2.1.5)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch<3.0.0,>=2.1.0->msclap) (1.3.0)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa<0.11.0,>=0.10.1->msclap) (2.22)\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"from msclap import CLAP\n\n# Load model (Choose between versions '2022' or '2023')\n# The model weight will be downloaded automatically if `model_fp` is not specified\nclap_model = CLAP(version = '2023', use_cuda=False)","metadata":{"execution":{"iopub.status.busy":"2024-09-12T08:38:26.193433Z","iopub.execute_input":"2024-09-12T08:38:26.193887Z","iopub.status.idle":"2024-09-12T08:38:30.000460Z","shell.execute_reply.started":"2024-09-12T08:38:26.193843Z","shell.execute_reply":"2024-09-12T08:38:29.999230Z"},"trusted":true},"outputs":[],"execution_count":43},{"cell_type":"code","source":"# Extract text embeddings\ntext_embeddings = clap_model.get_text_embeddings( [\"Carl's Jr\", \"Target Corporation\", \"Castrol\", \"China Unicom\", \"Woman Speaking in English\"])\n\n# Extract audio embeddings\naudio_embeddings = clap_model.get_audio_embeddings(['/kaggle/input/business-json/aud_files/kaggle/working/TTS/aud_files/sentence_40.wav'])\n\n# Compute similarity between audio and text embeddings \nsimilarities = clap_model.compute_similarity(audio_embeddings, text_embeddings)","metadata":{"execution":{"iopub.status.busy":"2024-09-12T08:55:38.399560Z","iopub.execute_input":"2024-09-12T08:55:38.400624Z","iopub.status.idle":"2024-09-12T08:55:39.339377Z","shell.execute_reply.started":"2024-09-12T08:55:38.400573Z","shell.execute_reply":"2024-09-12T08:55:39.338097Z"},"trusted":true},"outputs":[],"execution_count":68},{"cell_type":"code","source":"print(similarities)","metadata":{"execution":{"iopub.status.busy":"2024-09-12T08:55:39.801062Z","iopub.execute_input":"2024-09-12T08:55:39.802619Z","iopub.status.idle":"2024-09-12T08:55:39.809528Z","shell.execute_reply.started":"2024-09-12T08:55:39.802563Z","shell.execute_reply":"2024-09-12T08:55:39.808332Z"},"trusted":true},"outputs":[{"name":"stdout","text":"tensor([[5.8349, 6.7418, 2.2991, 5.9721, 7.4665]], grad_fn=<PermuteBackward0>)\n","output_type":"stream"}],"execution_count":69},{"cell_type":"code","source":"input_df = pd.read_csv(\"/kaggle/input/business-json/Test (1).csv\")\nentities_df = pd.read_csv(\"/kaggle/input/business-json/Knowledge.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-09-12T08:39:11.300158Z","iopub.execute_input":"2024-09-12T08:39:11.300626Z","iopub.status.idle":"2024-09-12T08:39:11.349439Z","shell.execute_reply.started":"2024-09-12T08:39:11.300584Z","shell.execute_reply":"2024-09-12T08:39:11.348218Z"},"trusted":true},"outputs":[],"execution_count":46},{"cell_type":"code","source":"import torch","metadata":{"execution":{"iopub.status.busy":"2024-09-12T08:39:11.648782Z","iopub.execute_input":"2024-09-12T08:39:11.649280Z","iopub.status.idle":"2024-09-12T08:39:11.654944Z","shell.execute_reply.started":"2024-09-12T08:39:11.649236Z","shell.execute_reply":"2024-09-12T08:39:11.653560Z"},"trusted":true},"outputs":[],"execution_count":47},{"cell_type":"code","source":"text_inputs = entities_df['Knowledge'].tolist()\ntext_embeddings = []\nfor i in text_inputs:\n    text_embeddings.append(clap_model.get_text_embeddings([i]))\ntext_embeddings = torch.cat(text_embeddings, dim=0)","metadata":{"execution":{"iopub.status.busy":"2024-09-12T08:39:45.422998Z","iopub.execute_input":"2024-09-12T08:39:45.423462Z","iopub.status.idle":"2024-09-12T08:41:27.040524Z","shell.execute_reply.started":"2024-09-12T08:39:45.423421Z","shell.execute_reply":"2024-09-12T08:41:27.039414Z"},"trusted":true},"outputs":[],"execution_count":51},{"cell_type":"code","source":"# import ast\n# import numpy as np\n# from tqdm import tqdm  # Import tqdm for the progress bar\n\n# # Loop through each sentence in the input_df with tqdm for progress tracking\n# top1_correct = 0\n# top5_correct = 0\n# top10_correct = 0\n# total_sentences = len(input_df)\n# audio_dir = \"/kaggle/input/business-json/aud_files/kaggle/working/TTS/aud_files/\"\n\n# # Using tqdm to track progress\n# for index, row in tqdm(input_df.iterrows(), total=total_sentences, desc=\"Processing Sentences\"):\n#     # Extract audio filename and the actual entities for the sentence\n#     audio_filename = audio_dir + str(row['audio_filename'])\n#     actual_entities = [entity_dict['link'] for entity_dict in ast.literal_eval(row['entities'])]\n#     print(actual_entities)\n#     print(type(actual_entities[0]))\n#     # Extract audio embeddings for the current audio file\n#     audio_embeddings = clap_model.get_audio_embeddings([audio_filename])\n    \n#     # Compute similarity between audio and text embeddings\n#     similarities = clap_model.compute_similarity(audio_embeddings, text_embeddings)\n#     # Get top indices for Top1, Top5, and Top10\n#     top_indices = np.argsort(similarities.detach().numpy(), axis=1)[::-1][0]\n#     top1_indices = top_indices[:1]\n#     top5_indices = top_indices[:5]\n#     top10_indices = top_indices[:10]\n    \n#     # Get the predicted top entity names\n#     top1_entity = entities_df.iloc[top1_indices[0]]['Entity_ID']\n#     top5_entities = entities_df.iloc[top5_indices]['Entity_ID'].tolist()\n#     top10_entities = entities_df.iloc[top10_indices]['Entity_ID'].tolist()\n#     print(top1_entity)\n#     # Check if the actual entities are present in Top1, Top5, and Top10\n#     if top1_entity in actual_entities:\n#         top1_correct += 1\n#     if any(entity in actual_entities for entity in top5_entities):\n#         top5_correct += 1\n#     if any(entity in actual_entities for entity in top10_entities):\n#         top10_correct += 1\n\n# # Calculate accuracy\n# top1_accuracy = top1_correct / total_sentences\n# top5_accuracy = top5_correct / total_sentences\n# top10_accuracy = top10_correct / total_sentences\n\n# # Print the results\n# print(f\"Top1 Accuracy: {top1_accuracy:.2f}\")\n# print(f\"Top5 Accuracy: {top5_accuracy:.2f}\")\n# print(f\"Top10 Accuracy: {top10_accuracy:.2f}\")\n","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-09-12T08:41:27.043327Z","iopub.execute_input":"2024-09-12T08:41:27.044038Z","iopub.status.idle":"2024-09-12T08:41:27.051770Z","shell.execute_reply.started":"2024-09-12T08:41:27.043980Z","shell.execute_reply":"2024-09-12T08:41:27.050565Z"},"trusted":true},"outputs":[],"execution_count":52},{"cell_type":"code","source":"# print(top1_correct)","metadata":{"execution":{"iopub.status.busy":"2024-09-12T08:41:27.053571Z","iopub.execute_input":"2024-09-12T08:41:27.054079Z","iopub.status.idle":"2024-09-12T08:41:27.069957Z","shell.execute_reply.started":"2024-09-12T08:41:27.054026Z","shell.execute_reply":"2024-09-12T08:41:27.068907Z"},"trusted":true},"outputs":[],"execution_count":53},{"cell_type":"code","source":"# text_inputs = entities_df['Entity_name'].tolist()\n# text_embeddings = []\n# for i in text_inputs:\n#     text_embeddings.append(clap_model.get_text_embeddings([i]))\n# text_embeddings = torch.cat(text_embeddings, dim=0)","metadata":{"execution":{"iopub.status.busy":"2024-09-12T08:41:27.073094Z","iopub.execute_input":"2024-09-12T08:41:27.074154Z","iopub.status.idle":"2024-09-12T08:41:27.083857Z","shell.execute_reply.started":"2024-09-12T08:41:27.074108Z","shell.execute_reply":"2024-09-12T08:41:27.082639Z"},"trusted":true},"outputs":[],"execution_count":54},{"cell_type":"code","source":"# import ast\n# import numpy as np\n# from tqdm import tqdm  # Import tqdm for the progress bar\n\n# # Loop through each sentence in the input_df with tqdm for progress tracking\n# top1_correct = 0\n# top5_correct = 0\n# top10_correct = 0\n# total_sentences = len(input_df)\n# audio_dir = \"/kaggle/input/business-json/aud_files/kaggle/working/TTS/aud_files/\"\n\n# # Using tqdm to track progress\n# for index, row in tqdm(input_df.iterrows(), total=total_sentences, desc=\"Processing Sentences\"):\n#     # Extract audio filename and the actual entities for the sentence\n#     audio_filename = audio_dir + str(row['audio_filename'])\n#     actual_entities = [entity_dict['mention'] for entity_dict in ast.literal_eval(row['entities'])]\n\n#     # Extract audio embeddings for the current audio file\n#     audio_embeddings = clap_model.get_audio_embeddings([audio_filename])\n    \n#     # Compute similarity between audio and text embeddings\n#     similarities = clap_model.compute_similarity(audio_embeddings, text_embeddings)\n    \n#     # Get top indices for Top1, Top5, and Top10\n#     top_indices = np.argsort(similarities.detach().numpy(), axis=1)[::-1][0]\n#     top1_indices = top_indices[:1]\n#     top5_indices = top_indices[:5]\n#     top10_indices = top_indices[:10]\n    \n#     # Get the predicted top entity names\n#     top1_entity = entities_df.iloc[top1_indices[0]]['Entity_name']\n#     top5_entities = entities_df.iloc[top5_indices]['Entity_name'].tolist()\n#     top10_entities = entities_df.iloc[top10_indices]['Entity_name'].tolist()\n\n#     # Check if the actual entities are present in Top1, Top5, and Top10\n#     if top1_entity in actual_entities:\n#         top1_correct += 1\n#     if any(entity in actual_entities for entity in top5_entities):\n#         top5_correct += 1\n#     if any(entity in actual_entities for entity in top10_entities):\n#         top10_correct += 1\n\n# # Calculate accuracy\n# top1_accuracy = top1_correct / total_sentences\n# top5_accuracy = top5_correct / total_sentences\n# top10_accuracy = top10_correct / total_sentences\n\n# # Print the results\n# print(f\"Top1 Accuracy: {top1_accuracy:.2f}\")\n# print(f\"Top5 Accuracy: {top5_accuracy:.2f}\")\n# print(f\"Top10 Accuracy: {top10_accuracy:.2f}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-12T08:41:27.085665Z","iopub.execute_input":"2024-09-12T08:41:27.086038Z","iopub.status.idle":"2024-09-12T08:41:27.098405Z","shell.execute_reply.started":"2024-09-12T08:41:27.085999Z","shell.execute_reply":"2024-09-12T08:41:27.097174Z"},"trusted":true},"outputs":[],"execution_count":55},{"cell_type":"code","source":"asr_df = pd.read_csv(\"/kaggle/input/business-json/asr_out.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-09-12T08:41:27.099932Z","iopub.execute_input":"2024-09-12T08:41:27.100363Z","iopub.status.idle":"2024-09-12T08:41:27.121946Z","shell.execute_reply.started":"2024-09-12T08:41:27.100308Z","shell.execute_reply":"2024-09-12T08:41:27.120715Z"},"trusted":true},"outputs":[],"execution_count":56},{"cell_type":"code","source":"print(asr_df)","metadata":{"execution":{"iopub.status.busy":"2024-09-12T08:41:27.123461Z","iopub.execute_input":"2024-09-12T08:41:27.123861Z","iopub.status.idle":"2024-09-12T08:41:27.133745Z","shell.execute_reply.started":"2024-09-12T08:41:27.123820Z","shell.execute_reply":"2024-09-12T08:41:27.132361Z"},"trusted":true},"outputs":[{"name":"stdout","text":"      Unnamed: 0  Sentence_ID  \\\n0              0            1   \n1              1            2   \n2              2            3   \n3              3            4   \n4              4            5   \n...          ...          ...   \n2621        2621         2622   \n2622        2622         2623   \n2623        2623         2624   \n2624        2624         2625   \n2625        2625         2626   \n\n                                             ASR_Output  \n0                   CARLS JUNIOR IS A TYPE OF RESTORENT  \n1          KARLS JUNIOR HAS HEADQUARTERS IN CARPENTERIA  \n2                 CARLS JUNIOR HAS THE SEO CARL CARCHER  \n3     KARL'S JUNIOR WAS ESTABLISHED ON NINETEEN FORT...  \n4        KARLS JUNIOR BELONGS TO THE FAST FOOD INDUSTRY  \n...                                                 ...  \n2621                          ROLLEXIS FROM SWITZERLAND  \n2622                                               TTRE  \n2623  SUMITUMA ELECTRIC INDUSTRIES WAS ESTABLISHED O...  \n2624  SUMITIMO ELECTRIC INDUSTRIES BELONGS TO THE NO...  \n2625        SUMITIMO ELECTRIC INDUSTRIES IS FROM JAPPIN  \n\n[2626 rows x 3 columns]\n","output_type":"stream"}],"execution_count":57},{"cell_type":"code","source":"import ast\nimport numpy as np\nfrom tqdm import tqdm  # Import tqdm for the progress bar\n\n# Loop through each sentence in the input_df with tqdm for progress tracking\ntop1_correct = 0\ntop5_correct = 0\ntop10_correct = 0\ntotal_sentences = len(input_df)\n\n# Using tqdm to track progress\nfor index, row in tqdm(input_df.iterrows(), total=total_sentences, desc=\"Processing Sentences\"):\n    # Extract audio filename and the actual entities for the sentence\n    asr_ot = str(asr_df.iloc[index]['ASR_Output'])\n    actual_entities = [entity_dict['mention'] for entity_dict in ast.literal_eval(row['entities'])]\n\n    # Extract audio embeddings for the current audio file\n    sent_embeddings = clap_model.get_text_embeddings([asr_ot])\n    \n    # Compute similarity between audio and text embeddings\n    similarities = clap_model.compute_similarity(sent_embeddings, text_embeddings)\n    # Get top indices for Top1, Top5, and Top10\n    top_indices = np.argsort(similarities.detach().numpy(), axis=1)[::-1][0]\n    top1_indices = top_indices[:1]\n    top5_indices = top_indices[:5]\n    top10_indices = top_indices[:10]\n    \n    # Get the predicted top entity names\n    top1_entity = entities_df.iloc[top1_indices[0]]['Entity_name']\n    top5_entities = entities_df.iloc[top5_indices]['Entity_name'].tolist()\n    top10_entities = entities_df.iloc[top10_indices]['Entity_name'].tolist()\n\n    # Check if the actual entities are present in Top1, Top5, and Top10\n    if top1_entity in actual_entities:\n        top1_correct += 1\n    if any(entity in actual_entities for entity in top5_entities):\n        top5_correct += 1\n    if any(entity in actual_entities for entity in top10_entities):\n        top10_correct += 1\n\n# Calculate accuracy\ntop1_accuracy = top1_correct / total_sentences\ntop5_accuracy = top5_correct / total_sentences\ntop10_accuracy = top10_correct / total_sentences\n\n# Print the results\nprint(f\"Top1 Accuracy: {top1_accuracy:.5f}\")\nprint(f\"Top5 Accuracy: {top5_accuracy:.5f}\")\nprint(f\"Top10 Accuracy: {top10_accuracy:.5f}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-12T08:42:18.065004Z","iopub.execute_input":"2024-09-12T08:42:18.065468Z","iopub.status.idle":"2024-09-12T08:51:14.803548Z","shell.execute_reply.started":"2024-09-12T08:42:18.065422Z","shell.execute_reply":"2024-09-12T08:51:14.802316Z"},"trusted":true},"outputs":[{"name":"stderr","text":"Processing Sentences: 100%|██████████| 2626/2626 [08:56<00:00,  4.89it/s]","output_type":"stream"},{"name":"stdout","text":"Top1 Accuracy: 0.00\nTop5 Accuracy: 0.00\nTop10 Accuracy: 0.00\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":59},{"cell_type":"code","source":"print(top1_correct,\ntop5_correct,\ntop10_correct)","metadata":{"execution":{"iopub.status.busy":"2024-09-12T08:53:09.861431Z","iopub.execute_input":"2024-09-12T08:53:09.862594Z","iopub.status.idle":"2024-09-12T08:53:09.868105Z","shell.execute_reply.started":"2024-09-12T08:53:09.862539Z","shell.execute_reply":"2024-09-12T08:53:09.866720Z"},"trusted":true},"outputs":[{"name":"stdout","text":"1 5 10\n","output_type":"stream"}],"execution_count":62},{"cell_type":"code","source":"print(f\"Top1 Accuracy: {top1_accuracy:.5f}\")\nprint(f\"Top5 Accuracy: {top5_accuracy:.5f}\")\nprint(f\"Top10 Accuracy: {top10_accuracy:.5f}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-12T08:53:41.973829Z","iopub.execute_input":"2024-09-12T08:53:41.974305Z","iopub.status.idle":"2024-09-12T08:53:41.980565Z","shell.execute_reply.started":"2024-09-12T08:53:41.974264Z","shell.execute_reply":"2024-09-12T08:53:41.979295Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Top1 Accuracy: 0.00038\nTop5 Accuracy: 0.00190\nTop10 Accuracy: 0.00381\n","output_type":"stream"}],"execution_count":63},{"cell_type":"code","source":"print(text_embeddings.shape)\nprint(sent_embeddings.shape)","metadata":{"execution":{"iopub.status.busy":"2024-09-12T08:52:29.186061Z","iopub.execute_input":"2024-09-12T08:52:29.186505Z","iopub.status.idle":"2024-09-12T08:52:29.193390Z","shell.execute_reply.started":"2024-09-12T08:52:29.186465Z","shell.execute_reply":"2024-09-12T08:52:29.191997Z"},"trusted":true},"outputs":[{"name":"stdout","text":"torch.Size([500, 1024])\ntorch.Size([1, 1024])\n","output_type":"stream"}],"execution_count":61},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}