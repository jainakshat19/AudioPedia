{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9339793,"sourceType":"datasetVersion","datasetId":5543066}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"### This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport warnings \nwarnings.filterwarnings(\"ignore\")\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-05T14:31:02.173137Z","iopub.execute_input":"2024-09-05T14:31:02.173542Z","iopub.status.idle":"2024-09-05T14:31:02.606334Z","shell.execute_reply.started":"2024-09-05T14:31:02.173499Z","shell.execute_reply":"2024-09-05T14:31:02.605172Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!git clone -b feature/add_hf https://github.com/nielsrogge/ImageBind.git\n%cd ImageBind","metadata":{"execution":{"iopub.status.busy":"2024-09-05T14:31:02.608654Z","iopub.execute_input":"2024-09-05T14:31:02.60971Z","iopub.status.idle":"2024-09-05T14:31:04.565938Z","shell.execute_reply.started":"2024-09-05T14:31:02.609656Z","shell.execute_reply":"2024-09-05T14:31:04.564514Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install .","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-09-05T14:31:04.568319Z","iopub.execute_input":"2024-09-05T14:31:04.568811Z","iopub.status.idle":"2024-09-05T14:40:57.195853Z","shell.execute_reply.started":"2024-09-05T14:31:04.568755Z","shell.execute_reply":"2024-09-05T14:40:57.194615Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from imagebind import data\nimport torch\nfrom imagebind.models import imagebind_model\nfrom imagebind.models.imagebind_model import ModalityType\nfrom imagebind.models.imagebind_model import ImageBindModel\n\ntext_list=[\"A dog.\", \"A car\", \"A bird\"]\nimage_paths=[\".assets/dog_image.jpg\", \".assets/car_image.jpg\", \".assets/bird_image.jpg\"]\naudio_paths=[\".assets/dog_audio.wav\", \".assets/car_audio.wav\", \".assets/bird_audio.wav\"]\n\ndevice = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n\nmodel = ImageBindModel.from_pretrained(\"nielsr/imagebind-huge\")\nmodel.eval()\nmodel.to(device)\n","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-09-05T14:40:57.199103Z","iopub.execute_input":"2024-09-05T14:40:57.200085Z","iopub.status.idle":"2024-09-05T14:41:57.132213Z","shell.execute_reply.started":"2024-09-05T14:40:57.200017Z","shell.execute_reply":"2024-09-05T14:41:57.130993Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Full Knowledge","metadata":{}},{"cell_type":"code","source":"import ast\ninput_df = pd.read_csv('/kaggle/input/business-json/Task_2_data.csv') \n# Function to extract entity names\ndef extract_entity_name(entities_str):\n    entities_list = ast.literal_eval(entities_str)\n    # Return the first two mentions if they exist, otherwise None\n    return (entities_list[0], entities_list[1]) if len(entities_list) > 1 else (entities_list[0], None)\n\n# Apply the function to the 'entities' column and expand into two new columns\ninput_df[['sentence_1_entity_name', 'sentence_2_entity_name']] = input_df['entity_titles'].apply(extract_entity_name).apply(pd.Series)\n\n# Display the updated DataFrame\nprint(input_df)\nentity_df = pd.read_csv('/kaggle/input/business-json/Knowledge.csv')\nasr_df = pd.read_csv(\"/kaggle/input/business-json/task_2_asr_out.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-09-05T14:41:57.133831Z","iopub.execute_input":"2024-09-05T14:41:57.134221Z","iopub.status.idle":"2024-09-05T14:41:57.302897Z","shell.execute_reply.started":"2024-09-05T14:41:57.134182Z","shell.execute_reply":"2024-09-05T14:41:57.301577Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport torch\nfrom imagebind.models.imagebind_model import ModalityType, ImageBindModel\nfrom imagebind import data\nimport pandas as pd\nfrom tqdm import tqdm\ndevice = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# Function to process audio files in batches\ndef process_audio_in_batches(txt, batch_size=16):\n    all_embeddings = []\n    for i in tqdm(range(0, len(txt), batch_size), desc=\"Processing Batches\"):\n        batch_txt = txt[i:i + batch_size]\n        embed_inputs = data.load_and_transform_text(batch_txt, device)\n        \n        with torch.no_grad():\n            embeddings = model({\n                ModalityType.TEXT: embed_inputs,\n            })\n        \n        all_embeddings.append(embeddings[ModalityType.TEXT])\n        torch.cuda.empty_cache()\n    \n    return torch.cat(all_embeddings, dim = 0)\n\n# # Process entity audio files in batches\nentity_embeddings= process_audio_in_batches(entity_df['Knowledge'].tolist())\n\n# Process sentence audio files in batches\ninput1_embeddings  = process_audio_in_batches(asr_df['Sentence_1_transcript'].tolist())\ninput2_embeddings = process_audio_in_batches(asr_df['Sentence_2_transcript'].tolist())\n","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-09-05T14:42:50.179801Z","iopub.execute_input":"2024-09-05T14:42:50.180754Z","iopub.status.idle":"2024-09-05T14:43:21.320812Z","shell.execute_reply.started":"2024-09-05T14:42:50.180708Z","shell.execute_reply":"2024-09-05T14:43:21.319605Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Initialize counters for ranking accuracy\ntop1_correct = 0\ntop5_correct = 0\ntop10_correct = 0\n\nres_data = []\n\n# Step 3: Calculate cosine similarity and evaluate rankings\nfor i, q_id in enumerate(input_df['QID']):\n    # Get the similarity scores for the current sentence with all entities\n    similarity_scores1 = cosine_similarity(input1_embeddings[i].unsqueeze(0).cpu().numpy(), entity_embeddings.cpu().numpy()).flatten()\n    similarity_scores2 = cosine_similarity(input2_embeddings[i].unsqueeze(0).cpu().numpy(), entity_embeddings.cpu().numpy()).flatten()\n    # Get the indices of entities sorted by similarity score (descending order)\n    ranked_entity_indices1 = similarity_scores1.argsort()[::-1]\n    ranked_entity_indices2 = similarity_scores2.argsort()[::-1]\n    # Get the ranked entity names\n    ranked_entity_names1 = entity_df['Entity_name'].iloc[ranked_entity_indices1]\n    ranked_entity_names2 = entity_df['Entity_name'].iloc[ranked_entity_indices2]\n\n    # Get the actual entity name for the current sentence\n    actual_entity_name1 = input_df['sentence_1_entity_name'].iloc[i]\n    actual_entity_name2 = input_df['sentence_2_entity_name'].iloc[i]\n    \n    res_data.append(\n    {\n        'q_id': q_id,\n        'linked_entity_sentnece_1': ranked_entity_names1.iloc[0],\n        'actual_entity_sentence_1' : actual_entity_name1,\n        'linked_entity_sentnece_2': ranked_entity_names2.iloc[0],\n        'actual_entity_sentence_2' : actual_entity_name2,\n    }\n    )\n    # Step 4: Check if the actual entity is within the top 1, 5, and 10\n    if actual_entity_name1 == ranked_entity_names1.iloc[0]:\n        top1_correct += 1\n    if actual_entity_name1 in ranked_entity_names1.iloc[:5].values:\n        top5_correct += 1\n    if actual_entity_name1 in ranked_entity_names1.iloc[:10].values:\n        top10_correct += 1\n        \n    if actual_entity_name2 == ranked_entity_names2.iloc[0]:\n        top1_correct += 1\n    if actual_entity_name2 in ranked_entity_names2.iloc[:5].values:\n        top5_correct += 1\n    if actual_entity_name2 in ranked_entity_names2.iloc[:10].values:\n        top10_correct += 1\n\n\n# Step 5: Calculate and print ranking accuracies\ntotal_sentences = len(input_df)\n\ntop1_accuracy = top1_correct / total_sentences * 50\ntop5_accuracy = top5_correct / total_sentences * 50\ntop10_accuracy = top10_correct / total_sentences * 50\n\nprint(f\"Top-1 Accuracy: {top1_accuracy:.2f}%\")\nprint(f\"Top-5 Accuracy: {top5_accuracy:.2f}%\")\nprint(f\"Top-10 Accuracy: {top10_accuracy:.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2024-09-05T14:43:22.637586Z","iopub.execute_input":"2024-09-05T14:43:22.638666Z","iopub.status.idle":"2024-09-05T14:43:27.673677Z","shell.execute_reply.started":"2024-09-05T14:43:22.638614Z","shell.execute_reply":"2024-09-05T14:43:27.672011Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ner_df = pd.DataFrame(res_data)\nner_df.to_csv(\"Task2_asr_entity_linked_ImageBIND_results.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-09-05T14:43:27.682014Z","iopub.execute_input":"2024-09-05T14:43:27.68295Z","iopub.status.idle":"2024-09-05T14:43:27.711604Z","shell.execute_reply.started":"2024-09-05T14:43:27.682867Z","shell.execute_reply":"2024-09-05T14:43:27.709946Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Entity Label","metadata":{}},{"cell_type":"code","source":"\n# # Process entity audio files in batches\nentity_embeddings = process_audio_in_batches(entity_df['Entity_name'].tolist())\n\n# Process sentence audio files in batches\ninput1_embeddings  = process_audio_in_batches(asr_df['Sentence_1_transcript'].tolist())\ninput2_embeddings = process_audio_in_batches(asr_df['Sentence_2_transcript'].tolist())\n\n","metadata":{"execution":{"iopub.status.busy":"2024-09-05T14:43:33.201882Z","iopub.execute_input":"2024-09-05T14:43:33.202978Z","iopub.status.idle":"2024-09-05T14:44:04.267027Z","shell.execute_reply.started":"2024-09-05T14:43:33.202927Z","shell.execute_reply":"2024-09-05T14:44:04.265805Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Initialize counters for ranking accuracy\ntop1_correct = 0\ntop5_correct = 0\ntop10_correct = 0\n\nres_data = []\n\n# Step 3: Calculate cosine similarity and evaluate rankings\nfor i, q_id in enumerate(input_df['QID']):\n    # Get the similarity scores for the current sentence with all entities\n    similarity_scores1 = cosine_similarity(input1_embeddings[i].unsqueeze(0).cpu().numpy(), entity_embeddings.cpu().numpy()).flatten()\n    similarity_scores2 = cosine_similarity(input2_embeddings[i].unsqueeze(0).cpu().numpy(), entity_embeddings.cpu().numpy()).flatten()\n    # Get the indices of entities sorted by similarity score (descending order)\n    ranked_entity_indices1 = similarity_scores1.argsort()[::-1]\n    ranked_entity_indices2 = similarity_scores2.argsort()[::-1]\n    # Get the ranked entity names\n    ranked_entity_names1 = entity_df['Entity_name'].iloc[ranked_entity_indices1]\n    ranked_entity_names2 = entity_df['Entity_name'].iloc[ranked_entity_indices2]\n\n    # Get the actual entity name for the current sentence\n    actual_entity_name1 = input_df['sentence_1_entity_name'].iloc[i]\n    actual_entity_name2 = input_df['sentence_2_entity_name'].iloc[i]\n    \n    res_data.append(\n    {\n        'q_id': q_id,\n        'linked_entity_sentnece_1': ranked_entity_names1.iloc[0],\n        'actual_entity_sentence_1' : actual_entity_name1,\n        'linked_entity_sentnece_2': ranked_entity_names2.iloc[0],\n        'actual_entity_sentence_2' : actual_entity_name2,\n    }\n    )\n    # Step 4: Check if the actual entity is within the top 1, 5, and 10\n    if actual_entity_name1 == ranked_entity_names1.iloc[0]:\n        top1_correct += 1\n    if actual_entity_name1 in ranked_entity_names1.iloc[:5].values:\n        top5_correct += 1\n    if actual_entity_name1 in ranked_entity_names1.iloc[:10].values:\n        top10_correct += 1\n        \n    if actual_entity_name2 == ranked_entity_names2.iloc[0]:\n        top1_correct += 1\n    if actual_entity_name2 in ranked_entity_names2.iloc[:5].values:\n        top5_correct += 1\n    if actual_entity_name2 in ranked_entity_names2.iloc[:10].values:\n        top10_correct += 1\n\n\n# Step 5: Calculate and print ranking accuracies\ntotal_sentences = len(input_df)\n\ntop1_accuracy = top1_correct / total_sentences * 50\ntop5_accuracy = top5_correct / total_sentences * 50\ntop10_accuracy = top10_correct / total_sentences * 50\n\nprint(f\"Top-1 Accuracy: {top1_accuracy:.2f}%\")\nprint(f\"Top-5 Accuracy: {top5_accuracy:.2f}%\")\nprint(f\"Top-10 Accuracy: {top10_accuracy:.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2024-09-05T14:44:04.269632Z","iopub.execute_input":"2024-09-05T14:44:04.270073Z","iopub.status.idle":"2024-09-05T14:44:09.230672Z","shell.execute_reply.started":"2024-09-05T14:44:04.270028Z","shell.execute_reply":"2024-09-05T14:44:09.229213Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ner_df = pd.DataFrame(res_data)\nner_df.to_csv(\"Task2_asr_entity_linked_ImageBIND_label_results.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-09-05T14:44:09.233229Z","iopub.execute_input":"2024-09-05T14:44:09.234286Z","iopub.status.idle":"2024-09-05T14:44:09.252264Z","shell.execute_reply.started":"2024-09-05T14:44:09.234203Z","shell.execute_reply":"2024-09-05T14:44:09.250695Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Partial Knowledge","metadata":{}},{"cell_type":"code","source":"# Calculate the substring for the first 20% of each knowledge string\nentity_df['Knowledge_20'] = entity_df['Knowledge'].apply(lambda x: x[:int(len(x) * 0.2)])\n\n# # Process entity audio files in batches\nentity_embeddings = process_audio_in_batches(entity_df['Knowledge_20'].tolist())\n\n# Process sentence audio files in batches\ninput1_embeddings  = process_audio_in_batches(asr_df['Sentence_1_transcript'].tolist())\ninput2_embeddings = process_audio_in_batches(asr_df['Sentence_2_transcript'].tolist())\n\n","metadata":{"execution":{"iopub.status.busy":"2024-09-05T14:44:09.256524Z","iopub.execute_input":"2024-09-05T14:44:09.257727Z","iopub.status.idle":"2024-09-05T14:44:40.695825Z","shell.execute_reply.started":"2024-09-05T14:44:09.257643Z","shell.execute_reply":"2024-09-05T14:44:40.69461Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Initialize counters for ranking accuracy\ntop1_correct = 0\ntop5_correct = 0\ntop10_correct = 0\n\nres_data = []\n\n# Step 3: Calculate cosine similarity and evaluate rankings\nfor i, q_id in enumerate(input_df['QID']):\n    # Get the similarity scores for the current sentence with all entities\n    similarity_scores1 = cosine_similarity(input1_embeddings[i].unsqueeze(0).cpu().numpy(), entity_embeddings.cpu().numpy()).flatten()\n    similarity_scores2 = cosine_similarity(input2_embeddings[i].unsqueeze(0).cpu().numpy(), entity_embeddings.cpu().numpy()).flatten()\n    # Get the indices of entities sorted by similarity score (descending order)\n    ranked_entity_indices1 = similarity_scores1.argsort()[::-1]\n    ranked_entity_indices2 = similarity_scores2.argsort()[::-1]\n    # Get the ranked entity names\n    ranked_entity_names1 = entity_df['Entity_name'].iloc[ranked_entity_indices1]\n    ranked_entity_names2 = entity_df['Entity_name'].iloc[ranked_entity_indices2]\n\n    # Get the actual entity name for the current sentence\n    actual_entity_name1 = input_df['sentence_1_entity_name'].iloc[i]\n    actual_entity_name2 = input_df['sentence_2_entity_name'].iloc[i]\n    \n    res_data.append(\n    {\n        'q_id': q_id,\n        'linked_entity_sentnece_1': ranked_entity_names1.iloc[0],\n        'actual_entity_sentence_1' : actual_entity_name1,\n        'linked_entity_sentnece_2': ranked_entity_names2.iloc[0],\n        'actual_entity_sentence_2' : actual_entity_name2,\n    }\n    )\n    # Step 4: Check if the actual entity is within the top 1, 5, and 10\n    if actual_entity_name1 == ranked_entity_names1.iloc[0]:\n        top1_correct += 1\n    if actual_entity_name1 in ranked_entity_names1.iloc[:5].values:\n        top5_correct += 1\n    if actual_entity_name1 in ranked_entity_names1.iloc[:10].values:\n        top10_correct += 1\n        \n    if actual_entity_name2 == ranked_entity_names2.iloc[0]:\n        top1_correct += 1\n    if actual_entity_name2 in ranked_entity_names2.iloc[:5].values:\n        top5_correct += 1\n    if actual_entity_name2 in ranked_entity_names2.iloc[:10].values:\n        top10_correct += 1\n\n\n# Step 5: Calculate and print ranking accuracies\ntotal_sentences = len(input_df)\n\ntop1_accuracy = top1_correct / total_sentences * 50\ntop5_accuracy = top5_correct / total_sentences * 50\ntop10_accuracy = top10_correct / total_sentences * 50\n\nprint(f\"Top-1 Accuracy: {top1_accuracy:.2f}%\")\nprint(f\"Top-5 Accuracy: {top5_accuracy:.2f}%\")\nprint(f\"Top-10 Accuracy: {top10_accuracy:.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2024-09-05T14:44:40.697478Z","iopub.execute_input":"2024-09-05T14:44:40.697956Z","iopub.status.idle":"2024-09-05T14:44:45.740371Z","shell.execute_reply.started":"2024-09-05T14:44:40.697903Z","shell.execute_reply":"2024-09-05T14:44:45.739086Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ner_df = pd.DataFrame(res_data)\nner_df.to_csv(\"Task2_asr_entity_linked_ImageBIND_partial_knowledge_results.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-09-05T14:44:45.74207Z","iopub.execute_input":"2024-09-05T14:44:45.742897Z","iopub.status.idle":"2024-09-05T14:44:45.758535Z","shell.execute_reply.started":"2024-09-05T14:44:45.742835Z","shell.execute_reply":"2024-09-05T14:44:45.756725Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}